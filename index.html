<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="theme-color" content="#000000">
    <title>rohan panuganti</title>
    <!-- Keeping libraries available; blob tracking below uses Canvas 2D -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Nunito:ital,wght@0,200..1000;1,200..1000&display=swap');

        body,
        html {
            margin: 0;
            padding: 0;
            width: 100%;
            height: 100%;
            overflow: hidden;
            background: #000000;
            background: linear-gradient(135deg, #1a1a1a, #0d0d40);
            font-family: "Nunito", sans-serif;
            color: white;
            /* Ensure fullscreen on mobile devices */
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
        }

        /* Handle iPhone X and newer safe areas */
        body {
            padding-top: env(safe-area-inset-top);
            padding-bottom: env(safe-area-inset-bottom);
            padding-left: env(safe-area-inset-left);
            padding-right: env(safe-area-inset-right);
        }

        /* Fullscreen camera video */
        #cameraVideo {
            position: fixed;
            inset: 0;
            width: 100vw;
            height: 100vh;
            object-fit: cover;
            /* like background-size: cover */
            z-index: 1;
            background: black;
            /* in case camera not ready */
        }

        /* Overlay for boxes/labels/lines */
        #overlay {
            position: fixed;
            inset: 0;
            width: 100vw;
            height: 100vh;
            z-index: 2;
            pointer-events: none;
        }

        /* Small debug mask preview (hidden by default) */
        #maskPreview {
            position: fixed;
            right: 12px;
            bottom: 12px;
            width: 160px;
            height: 120px;
            background: #000;
            opacity: 0.7;
            z-index: 3;
            border: 1px solid rgba(255, 255, 255, 0.2);
            display: none;
        }

        /* Minimal hint area (can be toggled off) */
        #hint {
            position: fixed;
            top: max(10px, env(safe-area-inset-top));
            left: 50%;
            transform: translateX(-50%);
            color: rgba(255, 255, 255, 0.85);
            font-size: 14px;
            z-index: 4;
            text-align: center;
            padding: 6px 10px;
            background: rgba(0, 0, 0, 0.35);
            border-radius: 8px;
            backdrop-filter: blur(4px);
        }
    </style>
</head>

<body>
    <video id="cameraVideo" playsinline autoplay muted></video>
    <canvas id="overlay"></canvas>
    <canvas id="maskPreview"></canvas>
    <div id="hint"></div>
    <script type="module">
        import { FilesetResolver, ObjectDetector } from 'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0';

        // --- Fullscreen camera + MediaPipe Object Detection ---
        const videoEl = document.getElementById('cameraVideo');
        const overlay = document.getElementById('overlay');
        const octx = overlay.getContext('2d');
        const hint = document.getElementById('hint');

        let detector = null;
        let lastVideoTime = -1;
        let lastDetections = [];
        const targetFPS = 24;
        const frameIntervalMs = 1000 / targetFPS; // ~41.67ms
        let lastFrameTs = 0;

        function setHint(msg) {
            hint.textContent = msg || '';
            hint.style.display = msg ? 'block' : 'none';
        }

        function resizeCanvases() {
            const dpr = Math.max(1, window.devicePixelRatio || 1);
            overlay.width = Math.floor(window.innerWidth * dpr);
            overlay.height = Math.floor(window.innerHeight * dpr);
            overlay.style.width = window.innerWidth + 'px';
            overlay.style.height = window.innerHeight + 'px';
            octx.setTransform(dpr, 0, 0, dpr, 0, 0);
        }
        window.addEventListener('resize', resizeCanvases);

        function coverTransform() {
            const vw = videoEl.videoWidth || 1;
            const vh = videoEl.videoHeight || 1;
            const sw = window.innerWidth;
            const sh = window.innerHeight;
            const videoAspect = vw / vh;
            const screenAspect = sw / sh;
            let renderW, renderH, offsetX, offsetY;
            if (videoAspect > screenAspect) {
                renderH = sh; renderW = sh * videoAspect;
                offsetX = (sw - renderW) / 2; offsetY = 0;
            } else {
                renderW = sw; renderH = sw / videoAspect;
                offsetX = 0; offsetY = (sh - renderH) / 2;
            }
            return { vw, vh, sw, sh, renderW, renderH, offsetX, offsetY };
        }

        async function initCamera() {
            if (location.protocol !== 'https:' && location.hostname !== 'localhost' && location.hostname !== '127.0.0.1') {
                setHint('Tip: Camera may require HTTPS or localhost.');
            }
            const constraints = {
                video: { facingMode: 'user', width: { ideal: 640 }, height: { ideal: 480 } },
                audio: false
            };
            const stream = await navigator.mediaDevices.getUserMedia(constraints);
            videoEl.srcObject = stream;
            await videoEl.play();
            resizeCanvases();
        }

        async function initDetector() {
            setHint('Loading detector…');
            const vision = await FilesetResolver.forVisionTasks(
                'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm'
            );
            detector = await ObjectDetector.createFromOptions(vision, {
                baseOptions: {
                    modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/float16/1/efficientdet_lite0.tflite'
                },
                scoreThreshold: 0.40,
                maxResults: 50,
                runningMode: 'VIDEO'
            });
            setHint('Detecting objects…');
        }

        function drawDetections(detections) {
            octx.clearRect(0, 0, overlay.width, overlay.height);
            const tx = coverTransform();
            const toScreen = (x, y) => {
                const sx = tx.offsetX + (x / tx.vw) * tx.renderW;
                const sy = tx.offsetY + (y / tx.vh) * tx.renderH;
                return [sx, sy];
            };

            octx.strokeStyle = '#00c9ff';
            octx.lineWidth = 2;
            octx.font = '14px Nunito, system-ui, -apple-system, sans-serif';
            octx.fillStyle = '#ffffff';

            const centers = [];
            for (const det of detections || []) {
                const bb = det.boundingBox; // originX, originY, width, height
                const [x1, y1] = toScreen(bb.originX, bb.originY);
                const [x2, y2] = toScreen(bb.originX + bb.width, bb.originY + bb.height);
                const w = x2 - x1, h = y2 - y1;
                octx.strokeRect(x1, y1, w, h);
                const [cx, cy] = toScreen(bb.originX + bb.width / 2, bb.originY + bb.height / 2);
                centers.push({ x: cx, y: cy });
                const cat = (det.categories && det.categories[0]) || {};
                const name = cat.categoryName || 'object';
                const score = cat.score != null ? ` ${(cat.score * 100).toFixed(1)}%` : '';
                const label = `${name}${score}`;
                octx.fillText(label, x1 + 4, y1 - 6 < 0 ? y1 + 14 : y1 - 6);
            }

            // Connect by ascending Y
            centers.sort((a, b) => a.y - b.y);
            octx.strokeStyle = 'rgba(255,255,255,0.8)';
            octx.lineWidth = 1;
            octx.beginPath();
            for (let i = 0; i < centers.length; i++) {
                const c = centers[i];
                if (i === 0) octx.moveTo(c.x, c.y); else octx.lineTo(c.x, c.y);
            }
            octx.stroke();
        }

        async function main() {
            try {
                await initCamera();
                await initDetector();
            } catch (e) {
                console.error(e);
                setHint('Initialization failed. Check permissions/HTTPS.');
                return;
            }

            function loop(nowTs) {
                if (!detector) { requestAnimationFrame(loop); return; }
                if (videoEl.readyState >= 2) {
                    // Throttle to target FPS
                    if (!lastFrameTs || nowTs - lastFrameTs >= frameIntervalMs) {
                        const mpNow = performance.now();
                        if (videoEl.currentTime !== lastVideoTime) {
                            const result = detector.detectForVideo(videoEl, mpNow);
                            lastDetections = result?.detections || [];
                            lastVideoTime = videoEl.currentTime;
                        }
                        drawDetections(lastDetections);
                        lastFrameTs = nowTs;
                    } else {
                        // Still draw last results to keep UI responsive
                        drawDetections(lastDetections);
                    }
                }
                requestAnimationFrame(loop);
            }
            requestAnimationFrame(loop);
        }

        main();
    </script>
</body>

</html>